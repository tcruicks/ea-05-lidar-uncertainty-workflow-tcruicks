{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"images/earth-lab-logo-rgb.png\" width=\"150\" height=\"150\" />\n",
    "\n",
    "# Earth Analytics"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img style=\"float: left;\" src=\"images/colored-bar.png\"/>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This notebook provides code that allows comparaison of LIDAR Canopy Height Model tree height estimates to insitu tree height measurements.\n",
    "\n",
    "### Study locations are the low elevation [NEON SJER](https://www.neonscience.org/field-sites/sjer) study area in California and the mid-elevation [NEON SOAP](https://www.neonscience.org/field-sites/soap) study area in California. \n",
    "\n",
    "### Users of this notebook:   \n",
    "1. A sample data set from [EarthPy](https://earthpy.readthedocs.io/en/latest/earthpy-data-subsets.html) is downloaded to your local machine.  \n",
    "2. Change the study_site variable to either sjer or soap study sites.\n",
    "3. Change the buffer size in meters to adjust the number of lidar pixels to compute stats with.\n",
    "\n",
    "\n",
    "### Unresolved issues with the Notebook:\n",
    "1. In plotting.py, line 163.  I want to create a point showing the study site \"area of interest\".  Python throws a warning suggesting that there are two types of crs: geographics and projected.  I have tried the suggestion to use 'GeoSeries.to_crs()' to re-project geometries to a projected CRS before this operation, but this did not work.  I'm leaving it as is because the centroid plot is accurate enough for these purposes.\n",
    "2. In plotting.py, line 159.  I'm clipping the roads shapefile to the lidar file extent.  Python throws a future warning.  Ignoring it because it is out of my control unless there is an alternate way to clip.\n",
    "3. In plotting.py, line 188.  I wanted to add a legened to indicate the black lines are roads, but when I include a legend in various permutations, it takes python forever to figure it out and render it.  I've left it off for now.\n",
    "\n",
    "Code by Tyler Cruickshank (tcruicks@gmail.com)\n",
    "![Colored Bar](images/colored-bar.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import rasterstats as rs\n",
    "import rioxarray as rxr\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import xarray as xr\n",
    "import rioxarray as rxr\n",
    "import numpy as np\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "import plotting as plot\n",
    "from set_paths import set_paths\n",
    "from download_dataset import download_dataset\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Colored Bar](images/colored-bar.png)\n",
    "### Set Project Plotting styles.\n",
    "![Colored Bar](images/colored-bar.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set consistent plotting style for all code cells.\n",
    "sns.set_style(\"white\")\n",
    "sns.set(font_scale=1.5)\n",
    "plt.style.use('fivethirtyeight')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Here is the class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Processing:\n",
    "\n",
    "    def __init__(self, study_site, lidar_pth, insitu_pth, plots_pth, buf_size):\n",
    "        \"\"\" \n",
    "        Sets object attributes.\n",
    "        \n",
    "        Parameters:\n",
    "        -----------\n",
    "        lidar_pth: str\n",
    "            Path to the lidar file itself.\n",
    "        insitu_pth: str\n",
    "            Path to the insitu tree height data file itself.\n",
    "        plots_pth: str\n",
    "            Path to the study sites shapefile.\n",
    "        buf_size: int\n",
    "            Size in meteres of buffer around each study plot point.\n",
    "        Returns:\n",
    "        -------\n",
    "        lidar_chm_clean: dataarray\n",
    "            A cleaned up lidar file.\n",
    "        lidar_chm_stats_gdf: geodataframe\n",
    "            Contains zonal stats from lidar data.\n",
    "        \"\"\"\n",
    "        self.study_site = study_site\n",
    "        self.lidar_pth = lidar_pth\n",
    "        self.insitu_pth = insitu_pth\n",
    "        self.plots_pth = plots_pth\n",
    "        self.buf_size = buf_size\n",
    "\n",
    "    def lidar_stats(self, plots_gdf):\n",
    "        \"\"\" \n",
    "        Open, clean, compute tree height stats on lidar file.\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        plot_gdf: geodataframe\n",
    "            GDF with buffer geometery.\n",
    "        Returns:\n",
    "        -------\n",
    "        lidar_chm_clean: dataarray\n",
    "            New lidar file with zeros removed.\n",
    "        lidar_chm_stats_gdf: geodataframe\n",
    "            GDF containing lidar stats for buffered study sites.\n",
    "        \"\"\"\n",
    "        # Open lidar file.\n",
    "        lidar_chm = rxr.open_rasterio(self.lidar_pth, masked=True).squeeze()\n",
    "        # Clean up the lidar file.\n",
    "        lidar_chm_clean = lidar_chm.where(lidar_chm > 0, np.nan)\n",
    "        \n",
    "        # Compute the mean and max lidar values within the buffer.\n",
    "        lidar_chm_stats = rs.zonal_stats(\n",
    "            plots_gdf,\n",
    "            lidar_chm_clean.values,\n",
    "            stats=['mean', 'max'],\n",
    "            affine=lidar_chm_clean.rio.transform(),\n",
    "            geojson_out=True, nodata=0, copy_properties=True,\n",
    "        )\n",
    "        # Stick it in a dataframe.\n",
    "        lidar_chm_stats_gdf = gpd.GeoDataFrame.from_features(lidar_chm_stats)\n",
    "\n",
    "        # Rename df columns.\n",
    "        lidar_chm_stats_gdf.rename(\n",
    "            columns={'max': 'lidar_max',\n",
    "                     'mean': 'lidar_mean', 'ID': 'Plot_ID'},\n",
    "            inplace=True\n",
    "        )\n",
    "\n",
    "        return (lidar_chm_clean, lidar_chm_stats_gdf)\n",
    "\n",
    "    def insitu_stats(self):\n",
    "        \"\"\" \n",
    "        Calculates tree height stats fro mobservations.\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        insitu_stem_height_df: geodataframe\n",
    "            GDF with observed tree height stats.\n",
    "        \"\"\"\n",
    "\n",
    "        insitu_gdf = gpd.read_file(self.insitu_pth)\n",
    "\n",
    "        # Reduce the columns to only what we need.\n",
    "        insitu_gdf = (insitu_gdf[\n",
    "            [\"siteid\", \"sitename\", \"plotid\", \"stemheight\", \"scientificname\"]])\n",
    "\n",
    "        # This solves an oddity.  The 'stemheight' column is not coming out as numeric.\n",
    "        # We need to change the datatype to a float.  As a float .mean and .max will work.\n",
    "        insitu_gdf[\"stemheight\"] = pd.to_numeric(\n",
    "            insitu_gdf[\"stemheight\"], downcast=\"float\")\n",
    "\n",
    "        # Create a df to include max and mean height.\n",
    "        insitu_stem_height_df = (insitu_gdf.groupby(\n",
    "            'plotid')['stemheight'].agg(['max', 'mean']))\n",
    "\n",
    "        # Rename column names to be more explanatory/\n",
    "        insitu_stem_height_df.rename(\n",
    "            columns={\"mean\": \"insitu_mean\", \"max\": \"insitu_max\"},\n",
    "            inplace=True\n",
    "        )\n",
    "\n",
    "        # The index is plotid but we just want 0 ... 9 ...\n",
    "        insitu_stem_height_df = insitu_stem_height_df.reset_index()\n",
    "        insitu_stem_height_df.head()\n",
    "\n",
    "        return (insitu_stem_height_df)\n",
    "\n",
    "    def buffer(self):\n",
    "        \"\"\" \n",
    "        Creates a buffer around study site point locations.\n",
    "        Returns:\n",
    "        -------\n",
    "        plots_gdf: geodataframe\n",
    "            GDF containing study site point locations.\n",
    "        plot_buffer_path: str\n",
    "            Path to shapefule with buffered geometry.\n",
    "        \"\"\"\n",
    "        # Open sjer plot location file.\n",
    "        plots_gdf = gpd.read_file(self.plots_pth)\n",
    "        # reset the geometry to the buffer version.\n",
    "        plots_gdf.geometry = plots_gdf.geometry.buffer(self.buf_size)\n",
    "\n",
    "        # Name and location of the buffered insitu measurement sites.\n",
    "\n",
    "        # Create an output dir for created files.\n",
    "        output_path = os.path.join(os.getcwd(), 'outputs')\n",
    "        if not os.path.isdir(output_path):\n",
    "            os.makedir(output_path)\n",
    "\n",
    "        plot_buffer_path = os.path.join(output_path, \"plot_buffer.shp\")\n",
    "        # Create the buffered file.\n",
    "        plots_gdf.to_file(plot_buffer_path)\n",
    "\n",
    "        return (plots_gdf, plot_buffer_path)\n",
    "    \n",
    "    def merge(self, lidar_stats_gdf, insitu_stats_gdf):\n",
    "\n",
    "        # MERGE Insitu stats df with LIDAR stats df\n",
    "        # For the SOAP site, the ID column doesnt math the insitu ID column.\n",
    "        # The Lidar file column needs 'SOAP' text appended to the ID integer.\n",
    "\n",
    "        if (self.study_site == 'soap'):\n",
    "            ss = self.study_site.upper()\n",
    "            lidar_stats_gdf['Plot_ID'] = ss + lidar_stats_gdf['Plot_ID']\n",
    "\n",
    "        all_heights_gdf = lidar_stats_gdf.merge(\n",
    "            insitu_stats_gdf,\n",
    "            left_on='Plot_ID',\n",
    "            right_on='plotid')\n",
    "\n",
    "        return(all_heights_gdf)\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Colored Bar](images/colored-bar.png)\n",
    "### The Main Code Cell.  I've included two main code cells.  One for SJER and one for SOAP.  The user can edit study_site and buffer if desired.\n",
    "![Colored Bar](images/colored-bar.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SJER LIDAR DATA EXISTS.\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'plotid'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 24\u001b[0m\n\u001b[1;32m     20\u001b[0m (lidar_chm_clean, lidar_chm_stats_gdf) \u001b[39m=\u001b[39m sjer_analysis\u001b[39m.\u001b[39mlidar_stats(plots_gdf)\n\u001b[1;32m     21\u001b[0m (insitu_stem_height_df) \u001b[39m=\u001b[39m sjer_analysis\u001b[39m.\u001b[39minsitu_stats()\n\u001b[0;32m---> 24\u001b[0m (tree_height_stats_gdf) \u001b[39m=\u001b[39m sjer_analysis\u001b[39m.\u001b[39;49mmerge(lidar_chm_stats_gdf)\n\u001b[1;32m     26\u001b[0m \u001b[39m# Create plots\u001b[39;00m\n\u001b[1;32m     27\u001b[0m plot\u001b[39m.\u001b[39mcreate_comparison_plots(tree_height_stats_gdf, study_site)\n",
      "Cell \u001b[0;32mIn[3], line 145\u001b[0m, in \u001b[0;36mProcessing.merge\u001b[0;34m(self, lidar_stats_gdf)\u001b[0m\n\u001b[1;32m    142\u001b[0m     ss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstudy_site\u001b[39m.\u001b[39mupper()\n\u001b[1;32m    143\u001b[0m     lidar_stats_gdf[\u001b[39m'\u001b[39m\u001b[39mPlot_ID\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m ss \u001b[39m+\u001b[39m lidar_stats_gdf[\u001b[39m'\u001b[39m\u001b[39mPlot_ID\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m--> 145\u001b[0m all_heights_gdf \u001b[39m=\u001b[39m lidar_stats_gdf\u001b[39m.\u001b[39;49mmerge(\n\u001b[1;32m    146\u001b[0m     lidar_stats_gdf,\n\u001b[1;32m    147\u001b[0m     left_on\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mPlot_ID\u001b[39;49m\u001b[39m'\u001b[39;49m,\n\u001b[1;32m    148\u001b[0m     right_on\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39mplotid\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m    150\u001b[0m \u001b[39mreturn\u001b[39;00m(all_heights_gdf)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/geopandas/geodataframe.py:1470\u001b[0m, in \u001b[0;36mGeoDataFrame.merge\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1449\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m   1450\u001b[0m     \u001b[39mr\u001b[39m\u001b[39m\"\"\"Merge two ``GeoDataFrame`` objects with a database-style join.\u001b[39;00m\n\u001b[1;32m   1451\u001b[0m \n\u001b[1;32m   1452\u001b[0m \u001b[39m    Returns a ``GeoDataFrame`` if a geometry column is present; otherwise,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1468\u001b[0m \n\u001b[1;32m   1469\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1470\u001b[0m     result \u001b[39m=\u001b[39m DataFrame\u001b[39m.\u001b[39;49mmerge(\u001b[39mself\u001b[39;49m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1471\u001b[0m     geo_col \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_geometry_column_name\n\u001b[1;32m   1472\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(result, DataFrame) \u001b[39mand\u001b[39;00m geo_col \u001b[39min\u001b[39;00m result:\n",
      "File \u001b[0;32m/opt/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/pandas/core/frame.py:10090\u001b[0m, in \u001b[0;36mDataFrame.merge\u001b[0;34m(self, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m  10071\u001b[0m \u001b[39m@Substitution\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m  10072\u001b[0m \u001b[39m@Appender\u001b[39m(_merge_doc, indents\u001b[39m=\u001b[39m\u001b[39m2\u001b[39m)\n\u001b[1;32m  10073\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m  10086\u001b[0m     validate: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m  10087\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[1;32m  10088\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mpandas\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mcore\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mreshape\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mmerge\u001b[39;00m \u001b[39mimport\u001b[39;00m merge\n\u001b[0;32m> 10090\u001b[0m     \u001b[39mreturn\u001b[39;00m merge(\n\u001b[1;32m  10091\u001b[0m         \u001b[39mself\u001b[39;49m,\n\u001b[1;32m  10092\u001b[0m         right,\n\u001b[1;32m  10093\u001b[0m         how\u001b[39m=\u001b[39;49mhow,\n\u001b[1;32m  10094\u001b[0m         on\u001b[39m=\u001b[39;49mon,\n\u001b[1;32m  10095\u001b[0m         left_on\u001b[39m=\u001b[39;49mleft_on,\n\u001b[1;32m  10096\u001b[0m         right_on\u001b[39m=\u001b[39;49mright_on,\n\u001b[1;32m  10097\u001b[0m         left_index\u001b[39m=\u001b[39;49mleft_index,\n\u001b[1;32m  10098\u001b[0m         right_index\u001b[39m=\u001b[39;49mright_index,\n\u001b[1;32m  10099\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m  10100\u001b[0m         suffixes\u001b[39m=\u001b[39;49msuffixes,\n\u001b[1;32m  10101\u001b[0m         copy\u001b[39m=\u001b[39;49mcopy,\n\u001b[1;32m  10102\u001b[0m         indicator\u001b[39m=\u001b[39;49mindicator,\n\u001b[1;32m  10103\u001b[0m         validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[1;32m  10104\u001b[0m     )\n",
      "File \u001b[0;32m/opt/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/pandas/core/reshape/merge.py:110\u001b[0m, in \u001b[0;36mmerge\u001b[0;34m(left, right, how, on, left_on, right_on, left_index, right_index, sort, suffixes, copy, indicator, validate)\u001b[0m\n\u001b[1;32m     93\u001b[0m \u001b[39m@Substitution\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39mleft : DataFrame or named Series\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     94\u001b[0m \u001b[39m@Appender\u001b[39m(_merge_doc, indents\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n\u001b[1;32m     95\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmerge\u001b[39m(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    108\u001b[0m     validate: \u001b[39mstr\u001b[39m \u001b[39m|\u001b[39m \u001b[39mNone\u001b[39;00m \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    109\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame:\n\u001b[0;32m--> 110\u001b[0m     op \u001b[39m=\u001b[39m _MergeOperation(\n\u001b[1;32m    111\u001b[0m         left,\n\u001b[1;32m    112\u001b[0m         right,\n\u001b[1;32m    113\u001b[0m         how\u001b[39m=\u001b[39;49mhow,\n\u001b[1;32m    114\u001b[0m         on\u001b[39m=\u001b[39;49mon,\n\u001b[1;32m    115\u001b[0m         left_on\u001b[39m=\u001b[39;49mleft_on,\n\u001b[1;32m    116\u001b[0m         right_on\u001b[39m=\u001b[39;49mright_on,\n\u001b[1;32m    117\u001b[0m         left_index\u001b[39m=\u001b[39;49mleft_index,\n\u001b[1;32m    118\u001b[0m         right_index\u001b[39m=\u001b[39;49mright_index,\n\u001b[1;32m    119\u001b[0m         sort\u001b[39m=\u001b[39;49msort,\n\u001b[1;32m    120\u001b[0m         suffixes\u001b[39m=\u001b[39;49msuffixes,\n\u001b[1;32m    121\u001b[0m         indicator\u001b[39m=\u001b[39;49mindicator,\n\u001b[1;32m    122\u001b[0m         validate\u001b[39m=\u001b[39;49mvalidate,\n\u001b[1;32m    123\u001b[0m     )\n\u001b[1;32m    124\u001b[0m     \u001b[39mreturn\u001b[39;00m op\u001b[39m.\u001b[39mget_result(copy\u001b[39m=\u001b[39mcopy)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/pandas/core/reshape/merge.py:703\u001b[0m, in \u001b[0;36m_MergeOperation.__init__\u001b[0;34m(self, left, right, how, on, left_on, right_on, axis, left_index, right_index, sort, suffixes, indicator, validate)\u001b[0m\n\u001b[1;32m    696\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_cross \u001b[39m=\u001b[39m cross_col\n\u001b[1;32m    698\u001b[0m \u001b[39m# note this function has side effects\u001b[39;00m\n\u001b[1;32m    699\u001b[0m (\n\u001b[1;32m    700\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mleft_join_keys,\n\u001b[1;32m    701\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mright_join_keys,\n\u001b[1;32m    702\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mjoin_names,\n\u001b[0;32m--> 703\u001b[0m ) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_merge_keys()\n\u001b[1;32m    705\u001b[0m \u001b[39m# validate the merge keys dtypes. We may need to coerce\u001b[39;00m\n\u001b[1;32m    706\u001b[0m \u001b[39m# to avoid incompatible dtypes\u001b[39;00m\n\u001b[1;32m    707\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_coerce_merge_keys()\n",
      "File \u001b[0;32m/opt/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/pandas/core/reshape/merge.py:1162\u001b[0m, in \u001b[0;36m_MergeOperation._get_merge_keys\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1160\u001b[0m rk \u001b[39m=\u001b[39m cast(Hashable, rk)\n\u001b[1;32m   1161\u001b[0m \u001b[39mif\u001b[39;00m rk \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m-> 1162\u001b[0m     right_keys\u001b[39m.\u001b[39mappend(right\u001b[39m.\u001b[39;49m_get_label_or_level_values(rk))\n\u001b[1;32m   1163\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1164\u001b[0m     \u001b[39m# work-around for merge_asof(right_index=True)\u001b[39;00m\n\u001b[1;32m   1165\u001b[0m     right_keys\u001b[39m.\u001b[39mappend(right\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m/opt/miniconda3/envs/earth-analytics-python/lib/python3.8/site-packages/pandas/core/generic.py:1850\u001b[0m, in \u001b[0;36mNDFrame._get_label_or_level_values\u001b[0;34m(self, key, axis)\u001b[0m\n\u001b[1;32m   1844\u001b[0m     values \u001b[39m=\u001b[39m (\n\u001b[1;32m   1845\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39maxes[axis]\n\u001b[1;32m   1846\u001b[0m         \u001b[39m.\u001b[39mget_level_values(key)  \u001b[39m# type: ignore[assignment]\u001b[39;00m\n\u001b[1;32m   1847\u001b[0m         \u001b[39m.\u001b[39m_values\n\u001b[1;32m   1848\u001b[0m     )\n\u001b[1;32m   1849\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1850\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mKeyError\u001b[39;00m(key)\n\u001b[1;32m   1852\u001b[0m \u001b[39m# Check for duplicates\u001b[39;00m\n\u001b[1;32m   1853\u001b[0m \u001b[39mif\u001b[39;00m values\u001b[39m.\u001b[39mndim \u001b[39m>\u001b[39m \u001b[39m1\u001b[39m:\n",
      "\u001b[0;31mKeyError\u001b[0m: 'plotid'"
     ]
    }
   ],
   "source": [
    "# MAIN Code Cell ---------------------\n",
    "study_site = 'sjer'\n",
    "buffer = 20\n",
    "# ------------------------------------\n",
    "\n",
    "# Set all paths and directories for project.\n",
    "(home_dir, plots_path, insitu_path,\n",
    " lidar_chm_path, output_path, usa_bndry_path,\n",
    " states_bndry_path, roads_path,\n",
    " sjer_aoi_path) = set_paths(study_site)\n",
    "\n",
    "# Download dataset for project.\n",
    "download_dataset(home_dir)\n",
    "\n",
    "# Use the Class -----\n",
    "# Create an object out of the class\n",
    "sjer_analysis = Processing(study_site, lidar_chm_path, insitu_path, plots_path, buffer)\n",
    "# Call class methods on the class object.\n",
    "(plots_gdf, plot_buffer_path) = sjer_analysis.buffer()\n",
    "(lidar_chm_clean, lidar_chm_stats_gdf) = sjer_analysis.lidar_stats(plots_gdf)\n",
    "(insitu_stem_height_df) = sjer_analysis.insitu_stats()\n",
    "\n",
    "\n",
    "(tree_height_stats_gdf) = sjer_analysis.merge(lidar_chm_stats_gdf, insitu_stem_height_df)\n",
    "\n",
    "# Create plots\n",
    "plot.create_comparison_plots(tree_height_stats_gdf, study_site)\n",
    "\n",
    "# Quick plot of lidar and plot locations.\n",
    "plot.plot_maps(\n",
    "    lidar_chm_clean, plots_gdf, study_site,\n",
    "    usa_bndry_path, states_bndry_path,\n",
    "    roads_path, sjer_aoi_path\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MAIN Code Cell ---------------------\n",
    "\n",
    "# Edit these two variables -----------\n",
    "study_site = 'soap'\n",
    "buffer = 20\n",
    "# ------------------------------------\n",
    "\n",
    "# Set all paths and directories for project.\n",
    "(home_dir, plots_path, insitu_path,\n",
    " lidar_chm_path, output_path, usa_bndry_path,\n",
    " states_bndry_path, places_path, roads_path,\n",
    " aoi_path) = set_paths(study_site)\n",
    "\n",
    "# Download dataset for project.\n",
    "download_dataset(home_dir)\n",
    "\n",
    "# Create buffers around study plots.\n",
    "plots_gdf, plot_buffer_path = pr.create_buffered_plots(\n",
    "    plots_path, output_path, buffer)\n",
    "\n",
    "# calculate tree height stats from insitu obs.\n",
    "insitu_stem_height_df = pr.calculate_insitu_stats(insitu_path)\n",
    "\n",
    "# Calculate tree height stats from lidar.\n",
    "lidar_chm_clean, lidar_chm_stats_gdf = pr.calculate_lidar_zonal_stats(\n",
    "    lidar_chm_path, plot_buffer_path, ['Max', 'Mean'])\n",
    "\n",
    "# -------------- MERGE Insitu stats df with LIDAR stats df ---------------- #\n",
    "# The SOAP columns dont quite match.  The Lidar file column needs 'SOAP' appended.\n",
    "if (study_site == 'soap'):\n",
    "    ss = study_site.upper()\n",
    "    lidar_chm_stats_gdf['Plot_ID'] = ss + lidar_chm_stats_gdf['Plot_ID']\n",
    "\n",
    "all_heights_gdf = lidar_chm_stats_gdf.merge(\n",
    "    insitu_stem_height_df,\n",
    "    left_on='Plot_ID',\n",
    "    right_on='plotid')\n",
    "\n",
    "# Create tree height estimate comparison plots\n",
    "plot.create_comparison_plots(all_heights_gdf, study_site)\n",
    "\n",
    "# Plot of lidar and plot locations.\n",
    "plot.plot_maps(\n",
    "    lidar_chm_clean, plots_gdf, study_site,\n",
    "    usa_bndry_path, states_bndry_path,\n",
    "    roads_path, places_path, aoi_path\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1 Figure One: SJER mean vs max height -- Plots 1 and 2 Interpretation\n",
    "In the markdown cell below, answer the following questions:\n",
    "\n",
    "1. Looking at the plots above, which metric: mean or max height, has a stronger relationship or is closer to a one:one relationship?\n",
    "2. List one reason why mean or max (whatever you answered for question 1 above) has a stronger relationship.\n",
    "\n",
    "You answers can be brief -- a single word or sentence or two is fine. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANSWER\n",
    "1. The max height of LIDAR estimates vs. insitu measurement shows a stronger correlation.\n",
    "2. LIDAR is likely to estimate the tallest trees in a canopy more accurately compared to shorter trees because there is less possible signal inteference around the tops of the tallest trees."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2. Of all four relationships that you plotted above, which site (SOAP or SJER) and metric (mean or max height) showed the strongest relationship? \n",
    "\n",
    "**A strong relationship is one that is closer to 1:1 in this case.**\n",
    "\n",
    "Add your answer in the markdown cell below. It can be short - 2-5 sentences. You do not need to perform any additional calculations. Consider the readings and the data and suggest why a particular metric might have a strong relationship."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANSWER\n",
    "Max height has the strongest relationship by far.  The SJER and SOAP sites max height reationships to insitu observations are similar to each other.  There are outliers for both data sets but the majority of data points show a strong relationship.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3. List 2 reasons why lidar max height values may be larger than human measurements."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANSWER\n",
    "1. Human measurement techniques are ground-based and therefore trying to estimate tree heights through a canopoy can be difficult.  Canopy thickness can obscure tree tops.  Wind can make it difficult to estimate as the tree top sways back and forth."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4. List 2 systematic sources of error could impact differences between lidar and measured tree height values ( 5 points)\n",
    "\n",
    "Add your answer in the markdown cell below."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANSWER\n",
    "1. Assume stick method for insitu observation.  The observor, stick holder, might always hold the stick at a similar non-vertial angle.\n",
    "2. Wind moving the canopy top could produce significant systematic error in tree height estimate."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 5. List 2 random sources of error that could impact differences between lidar and measured tree height values.  (5 points)\n",
    "\n",
    "Add your answer to the markdown cell below. Note that you can provide sources of random error for lidar OR insitu measurements. You only need two total examples. "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANSWER\n",
    "1. Deciduous vs evergreen trees and foliage season will likely produce both systematic and random error.\n",
    "2. An observor using any type of tree height measurement will intoduce error at some stage of the estimation technique.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "earth-analytics-python",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  },
  "vscode": {
   "interpreter": {
    "hash": "a242e183465bb9023de0138d2b64ba329c59b510ac4eb42cc190969549979312"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
